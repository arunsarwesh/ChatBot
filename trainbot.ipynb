{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# Load the dataset from CSV\n",
    "df = pd.read_csv('association_dataset.csv')\n",
    "\n",
    "# Combine all text data into a single column for fine-tuning\n",
    "text_data = df['Content'].tolist()\n",
    "\n",
    "# Convert text data into a dataset format suitable for transformers\n",
    "dataset = Dataset.from_dict({\"text\": text_data})\n",
    "\n",
    "# Load the GPT-2 tokenizer and model\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)\n",
    "\n",
    "# Add padding token if needed (GPT-2 does not have a padding token by default)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_steps=10_000,\n",
    "    output_dir='./model',\n",
    "    overwrite_output_dir=True,\n",
    "    no_cuda=(device == \"cpu\"),  # Set this to True if CUDA is not available\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained('./model')\n",
    "tokenizer.save_pretrained('./model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the main goals of the student association?\n",
      "\n",
      "\n",
      "Our main objectives are to:\n",
      "\n",
      "Recruit top students from diverse disciplines within the community. We will ensure that our students and instructors are willing to mentor and mentor other students.\n",
      "\n",
      "\n",
      "Develop new initiatives and policies aimed at improving student success.\n",
      "\n",
      "\n",
      "Develop an impact statement regarding the specific objectives of the student association.\n",
      "\n",
      "\n",
      "Work with and participate in local leadership and other community initiatives.\n",
      "\n",
      "\n",
      "Work with local, state and federal law\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the tokenizer and model from the directory where you saved them\n",
    "model_dir = \"D:/stud bot/model\"  # Replace with the path to the downloaded model folder\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "\n",
    "# Generate text to evaluate the model\n",
    "input_text = \"What are the main goals of the student association?\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate text with the model\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'],\n",
    "    max_length=100,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True, \n",
    "    top_k=50,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
